{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "present-confidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.2.0-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\srish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\srish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\srish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "latest-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intermediate-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./spam.csv', encoding='ISO-8859-1')\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painful-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unknown-september",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ham',\n",
       "        'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "        nan, nan, nan],\n",
       "       ['ham', 'Ok lar... Joking wif u oni...', nan, nan, nan],\n",
       "       ['spam',\n",
       "        \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "        nan, nan, nan],\n",
       "       ...,\n",
       "       ['ham',\n",
       "        'Pity, * was in mood for that. So...any other suggestions?', nan,\n",
       "        nan, nan],\n",
       "       ['ham',\n",
       "        \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\",\n",
       "        nan, nan, nan],\n",
       "       ['ham', 'Rofl. Its true to its name', nan, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "embedded-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:,0]\n",
    "x = data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "supposed-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "velvet-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "sw = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "integral-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStemmedreview(review):\n",
    "    review = review.lower()\n",
    "    #tokenize\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    #stopword removal\n",
    "    new_tokens= [token for token in tokens if token not in sw]\n",
    "    #stemming\n",
    "    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fleet-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStemmedDocument(document):\n",
    "    d=[]\n",
    "    for doc in document:\n",
    "        d.append(getStemmedreview(doc))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "indian-investment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri question std txt rate c appli 08452810075over18',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_document = getStemmedDocument(x)\n",
    "stemmed_document[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "maritime-circle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "vectorized_corpus = cv.fit_transform(stemmed_document)\n",
    "x = vectorized_corpus.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "metropolitan-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "...     x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cubic-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ceramic-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "seventh-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977705274605764"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "superb-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"\n",
    "Hi Kunal,\n",
    "We invite you to participate in MishMash - India’s largest online diversity hackathon. \n",
    "The hackathon is a Skillenza initiative and sponsored by Microsoft, Unity, Unilever, Gojek, Rocketium and Jharkhand Government. \n",
    "We have a special theme for you - Deep Tech/Machine Learning - sponsored by Unilever, which will be perfect for you.\"\"\",\n",
    "    \n",
    "    \n",
    "    \"\"\"Join us today at 12:00 PM ET / 16:00 UTC for a Red Hat DevNation tech talk on AWS Lambda and serverless Java with Bill Burke.\n",
    "Have you ever tried Java on AWS Lambda but found that the cold-start latency and memory usage were far too high? \n",
    "In this session, we will show how we optimized Java for serverless applications by leveraging GraalVM with Quarkus to \n",
    "provide both supersonic startup speed and a subatomic memory footprint.\"\"\",\n",
    "\n",
    "    \"\"\"We really appreciate your interest and wanted to let you know that we have received your application.\n",
    "There is strong competition for jobs at Intel, and we receive many applications. As a result, it may take some time to get back to you.\n",
    "Whether or not this position ends up being a fit, we will keep your information per data retention policies, \n",
    "so we can contact you for other positions that align to your experience and skill set.\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "sharp-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_message(messages):\n",
    "    d = getStemmedDocument(messages)\n",
    "    # very very import, dont do fit_transform!\n",
    "    return cv.transform(d)\n",
    "\n",
    "messages = prepare_message(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "rapid-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "nasty-region",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-desert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
